# ABAE: Utilize Attention to Boost Graph Auto-Encoder

This is the code for the paper "**ABAE: Utilize Attention to Boost Graph Auto-Encoder, PRICAI 2021**". Our architecture is based on the encoder-decoder model. The components of this model are shown as follows.

![](https://i.loli.net/2021/06/10/exbZRm5M1iP2Fk8.png)

### Dependencies

- Python 3.7+
- Pytorch 1.7.0+
- Numpy 1.17.2+
- tqdm 4.41.1+



### Results

Our architecture has achieved state-of-the-art in *Link Prediction*. Total comparance is given.

![image-20210610103103064](https://i.loli.net/2021/06/10/6VUGZFHD2Jbxhmo.png)
